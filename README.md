# Denoising Diffusion Probabilistic Models (DDPM) - Advanced Course on Deep Generative Models

## Overview
This repository contains the implementation of Denoising Diffusion Probabilistic Models (DDPM) as part of the Advanced Course on Deep Generative Models, Spring 2024. The assignment focuses on understanding and implementing DDPMs using UNet architectures and includes training the model on the MNIST dataset. Additionally, probabilistic inference is performed to generate parts of images based on given partial data.

## Assignment Details

### Instructor
**Dan Rosenbaum**

### Due Date
**31 July 2024**

### Goals
1. **Understand DDPM Models**: Implement and train the DDPM model to generate samples from the MNIST dataset.
2. **UNet Architecture**: Implement a UNet model to estimate the noise for each step of the DDPM model.
3. **Sampling and Inference**: Generate complete samples of images from partial data, such as generating the bottom half of the image when given the top half.
4. **Bonus**: Implement a context-conditioned DDPM model using the CLIP model on the CelebA dataset.

### Instructions
- Implement the forward function for the **UNet architecture**.
- Complete the **DDPM functions**:
  - `q(xt|x0;t)`: Forward diffusion process.
  - `q(xt−1|xt;t,εt)`: Reverse diffusion process.
  - Loss calculation.
  - Image sampling.
- Train the model on **MNIST** for at least 20 epochs and report the training loss curve.
- Implement **probabilistic inference** to complete images using half of the data.
- **Bonus Task**: Use the CLIP model to condition the DDPM on textual prompts, generating samples from the **CelebA** dataset.


## Model Implementation

- **UNet**: The UNet architecture is implemented to estimate the score function, which is used to predict the noise at each step.
- **DDPM**: Functions for forward diffusion, reverse diffusion, loss calculation, and sampling are included. The model is trained on the MNIST dataset for 20 epochs.
- **Probabilistic Inference**: Implemented to generate half of the image, conditioned on the other half.

## Results

### MNIST Training
- After 20 epochs of training, samples generated by the model resemble valid digits.
- Loss curves and generated samples can be found in the `results/` directory.

### Probabilistic Inference
- Six images were selected, and half of the image was masked. The model was able to generate the missing half for both top and bottom halves, as required.

### Bonus: CLIP + CelebA
- The model was extended to work with the CelebA dataset and conditioned on text prompts using CLIP.
- Samples conditioned on text prompts and unconditional samples are available in the `results/` folder.

## Running the Code

To run the project:
1. Clone the repository.
   ```bash
   git clone https://github.com/your-repo/DDPM-assignment.git
   cd DDPM-assignment
2. Open main.ipynb in Google Colab or Jupyter Notebook.
3. Run all cells to train the model and generate results.
